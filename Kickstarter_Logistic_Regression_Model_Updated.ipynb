{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os \n",
    "from datetime import datetime\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedirectory = os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\ivann\\OneDrive\\Documents\\~General Assembly Documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"DSI_kickstarterscrape_dataset.csv\", encoding =\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()\n",
    "#two things you shoul always do, dataset.info() and dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_data.info())\n",
    "display(raw_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's update the data types on our raw data\n",
    "data_updated_dtype = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the project id from an integer to a string\n",
    "data_updated_dtype['project id'] = data_updated_dtype['project id'].astype('string')\n",
    "\n",
    "\n",
    "#let's put the day of the week into it's own column\n",
    "data_updated_dtype[['Day of Week','funded date']] = data_updated_dtype['funded date'].str.split(',',n=1,expand=True)\n",
    "#let's remove the annoying zeros at the end of the each entry\n",
    "data_updated_dtype['funded date']= data_updated_dtype['funded date'].str.rstrip('-0000')\n",
    "data_updated_dtype['Funded Date'] = pd.to_datetime(data_updated_dtype['funded date']).dt.date\n",
    "data_updated_dtype['Funded Time'] = pd.to_datetime(data_updated_dtype['funded date']).dt.time\n",
    "data_updated_dtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated_dtype.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's drop the original date time column\n",
    "data_updated_dtype.drop(columns = ['funded date'], inplace = True)\n",
    "data_updated_dtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated_dtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check to see what type of data we have\n",
    "data_updated_dtype.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated_dtype.isna().any() #let's check for missing values in our updated dtype data set\n",
    "#Expected output: \n",
    "# project id           False\n",
    "# name                 False\n",
    "# url                  False\n",
    "# category             False\n",
    "# subcategory          False\n",
    "# location              True\n",
    "# status               False\n",
    "# goal                 False\n",
    "# pledged               True\n",
    "# funded percentage    False\n",
    "# backers              False\n",
    "# levels               False\n",
    "# reward levels         True\n",
    "# updates              False\n",
    "# comments             False\n",
    "# duration             False\n",
    "# Day of Week          False\n",
    "# Funded Date          False\n",
    "# Funded Time          False\n",
    "# dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename two word columns to be correct\n",
    "data_updated_dtype[\"reward_levels\"]=data_updated_dtype['reward levels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove old reward levels column\n",
    "data_updated_dtype.drop(columns=['reward levels'],inplace=True, axis=1)\n",
    "data_updated_dtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the number of null values in a specific column\n",
    "pledged_null = data_updated_dtype.isnull().pledged.sum()\n",
    "location_null = data_updated_dtype.isnull().location.sum()\n",
    "reward_null = data_updated_dtype.isnull().reward_levels.sum()\n",
    "print(\"null location count\", location_null)\n",
    "print(\"pledged null\", pledged_null)  \n",
    "print (\"reward levels null\", reward_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's drop any rows that are missing locations, since we have no way to determine what the Location should be from the data we have.\n",
    "data_updated_dtype.dropna(subset=['location'],inplace=True)\n",
    "\n",
    "#let's double check that we removed all the null values\n",
    "location_null = data_updated_dtype.isnull().location.sum()\n",
    "print(\"null location count\", location_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's drop the rows missing reward levels since we have no way to calculate this as well.\n",
    "data_updated_dtype.dropna(subset=['reward_levels'],inplace=True)\n",
    "\n",
    "#let's double check that we removed all the null values\n",
    "reward_null = data_updated_dtype.isnull().reward_levels.sum()\n",
    "print (\"reward levels null\", reward_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now attempt to update the null pldeged values using Goal amount and funded percentage\n",
    "#call all rows that do not contain a pledged amount\n",
    "#Let's calculate a new column called \"Calculted_Pledged\" and compare that with the reported pldege amounts to see if they are \n",
    "#the same.\n",
    "data_updated_dtype['Calculated_Pledged']=round(data_updated_dtype['goal']*(data_updated_dtype['funded percentage']),0)\n",
    "data_updated_dtype['pledgedMatch?'] = np.where(data_updated_dtype['pledged'] == data_updated_dtype['Calculated_Pledged'], 'True', 'False')  \n",
    "#create new column in df1 to check if pledged amounts  match\n",
    "\n",
    "data_updated_dtype.sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's add in the pldged amount where appropiate in our dataset\n",
    "nullpledged_df = data_updated_dtype[data_updated_dtype.isnull().pledged]\n",
    "nullpledged_df.head(20) #there should only be 12 rows in the pledged null data frame\n",
    "# data_updated_dtype['pledged']=round(nullpledged_df['goal']*(nullpledged_df['funded percentage']),0)\n",
    "# pledged_null = data_updated_dtype.isnull().pledged.sum()\n",
    "# print(\"pledged null\", pledged_null)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's attempt to fill in the values for this temporary data frame\n",
    "#the following code snippet was me testing how to use the np.where function, which essentialy acts like an if-then function.\n",
    "#The function worked the way that I hoped it would\n",
    "# nullpledged_df['pledged'] = np.where(nullpledged_df['pledged'].isnull(),round(nullpledged_df['goal']*(nullpledged_df['funded percentage']),0),nullpledged_df['pledged'])\n",
    "# nullpledged_df.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the numpy \"where\" function to replace NAN values in the data set with by calculating pledged amount from fundraising goal * pledged percentage.\n",
    "data_updated_dtype['pledged'] = np.where(data_updated_dtype['pledged'].isnull(),round(data_updated_dtype['goal']*(data_updated_dtype['funded percentage']),0),data_updated_dtype['pledged'])\n",
    "pledged_null = data_updated_dtype.isnull().pledged.sum()\n",
    "#the expected output is 0. \n",
    "print(\"pledged null\", pledged_null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataset to be used for further data cleaning\n",
    "#We need to drop the extra columns we created, i.e. pledgedmatch? and calculated pledge\n",
    "data_updated_dtype.drop(columns= ['Calculated_Pledged','pledgedMatch?'], inplace=True)\n",
    "no_nulls_data= data_updated_dtype\n",
    "no_nulls_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Step: Let's make sure all categories are unique and consistent\n",
    "print(no_nulls_data.category.unique())\n",
    "print(no_nulls_data.groupby(['category'])['category'].count())\n",
    "#From our output, we see that Film & Video is written two ways, Film & Video + Film &amp; Video\n",
    "#The total expected amount of listings that fall in the Film & video category is 13,082\n",
    "#Expected output\n",
    "# category\n",
    "    # Art                  3872\n",
    "    # Comics               1034\n",
    "    # Dance                 744\n",
    "    # Design               1738\n",
    "    # Fashion              1117\n",
    "    # Film & Video          482\n",
    "    # Film &amp; Video    12600\n",
    "    # Food                 1411\n",
    "    # Games                1689\n",
    "    # Music               10671\n",
    "    # Photography          1424\n",
    "    # Publishing           4585\n",
    "    # Technology            774\n",
    "    # Theater              2451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relace all instances of Film &amp; Video with Film & Video\n",
    "no_nulls_data['category'] = np.where(no_nulls_data['category'] =='Film &amp; Video','Film & Video',no_nulls_data['category'])\n",
    "print(no_nulls_data.groupby(['category'])['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's identify the unique values of our subcategories\n",
    "# print(no_nulls_data.subcategory.unique())\n",
    "print(no_nulls_data.groupby(['subcategory'])['subcategory'].count())\n",
    "# print(no_nulls_data.loc[no_nulls_data['subcategory'] == 'Board & Card Games'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's redefine Board &amp; Card Games,  Country &amp; Folk  ,  Film &amp; Video\n",
    "no_nulls_data['subcategory'] = np.where(no_nulls_data['subcategory'] =='Film &amp; Video','Film & Video',no_nulls_data['subcategory'])\n",
    "no_nulls_data['subcategory'] = np.where(no_nulls_data['subcategory'] =='Country &amp; Folk','Country & Folk',no_nulls_data['subcategory'])\n",
    "no_nulls_data['subcategory'] = np.where(no_nulls_data['subcategory'] =='Board &amp; Card Games','Board & Card Games',no_nulls_data['subcategory'])\n",
    "\n",
    "# for item  in no_nulls_data['subcategory']:\n",
    "#     if (item == 'Film &amp; Video'):\n",
    "#         no_nulls_data['subcategory'][item]= ('Film & Video')\n",
    "#     else:\n",
    "#         item = item\n",
    "    \n",
    "# no_nulls_data.shape\n",
    "#In order to iterate over an index I need to reindex my code.\n",
    "no_nulls_data.reset_index(drop=True, inplace= True)\n",
    "no_nulls_data.head(20)\n",
    "# print(no_nulls_data['subcategory'][0]);\n",
    "# print(no_nulls_data['subcategory'][11]);\n",
    "# i = 0;\n",
    "# for i in range(len(no_nulls_data['subcategory'])):\n",
    "# #     print(no_nulls_data['category'][i])\n",
    "#     if no_nulls_data['subcategory'][i] == 'Film &amp; Video':\n",
    "#         no_nulls_data['subcategory'][i] =\"Film & Video\"\n",
    "#     elif no_nulls_data['subcategory'][i] == 'Board &amp; Card Games':\n",
    "#         no_nulls_data['subcategory'][i] = \"Board & Card Games\"\n",
    "#     elif no_nulls_data['subcategory'][i] == 'Country &amp; Folk':\n",
    "#         no_nulls_data['subcategory'][i] =\"Country & Folk\"\n",
    "# no_nulls_data.column = df.column.apply(<urstuff>)\n",
    "    \n",
    "        \n",
    "        \n",
    "#     if no_nulls_data['subcategory'][i] == 'Film &amp; Video':\n",
    "#         no_nulls_data['subcategory'][i] = \"Film & video\"\n",
    "#     else:\n",
    "#         no_nulls_data['subcategory'][i] = no_nulls_data['subcategory'][i]\n",
    "# no_nulls_data.head(20)\n",
    "#Print statement to make sure everything was renamed properly\n",
    "#print(no_nulls_data.subcategory.unique())\n",
    "no_nulls_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove extra columns if possible\n",
    "# print(no_nulls_data['pledgedMatch?'].is())\n",
    "# print(no_nulls_data['goal'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename no_null_data to the final dataset since everything is finally cleaned\n",
    "#Convert the the decimal repesentation of funded percentage to actually correspond with the percentage\n",
    "no_nulls_data['funded percentage']= no_nulls_data['funded percentage'].apply(lambda x: x*100)\n",
    "final_data=no_nulls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's describe our data set \n",
    "round(final_data.describe(),2)\n",
    "#             goal   \tpledged  \tfunded percentage\tbackers \tlevels  \tupdates \tcomments\tduration\n",
    "# count\t4.459200e+04\t4.459200e+04\t44592.000\t44592.000  \t44592.000\t44592.000\t44592.000\t44592.000\n",
    "# mean\t1.210894e+04\t5.104144e+03\t165.889 \t71.038  \t8.047\t4.069\t8.526\t39.628\n",
    "# std\t1.916062e+05\t5.769624e+04\t7634.553\t698.999  \t4.247\t6.404\t176.651\t17.087\n",
    "# min\t5.000000e-01\t0.000000e+00\t0.000   \t0.000   \t1.000\t0.000\t0.000\t1.000\n",
    "# 25%\t1.800000e+03\t2.000000e+02\t4.500   \t5.000   \t5.000\t0.000\t0.000\t30.000\n",
    "# 50%\t4.000000e+03\t1.326000e+03\t100.000 \t23.000  \t8.000\t2.000\t0.000\t31.605\n",
    "# 75%\t1.000000e+04\t4.205000e+03\t111.667 \t60.000  \t10.000\t6.000\t3.000\t47.020\n",
    "# max\t2.147484e+07\t1.026684e+07\t1506600.000\t87142.000\t80.000\t149.000\t19311.000\t91.960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['status'].unique()\n",
    "final_data\n",
    "#let's remove the rows that have live, cancelled, or suspended\n",
    "\n",
    "# get names of indexes for which \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = final_data[(final_data['status'] == \"live\") | (final_data['status'] == 'canceled') | (final_data['status'] == 'suspended')].index \n",
    "  \n",
    "# drop these given row \n",
    "# indexes from dataFrame \n",
    "final_data.drop(index_names, inplace = True) \n",
    "final_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "final_data\n",
    "# final_data['status'].unique()\n",
    "#Remove the rows that are not failed or successfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the value we are trying to calculate is binary\n",
    "sns.countplot(x = 'status', data = final_data)\n",
    "#check, each item is either successful or failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's drop the reward levels column and the location column to make things easier for us.\n",
    "#we are removing project name because I currently have no way to quanitify how good or bad a project name when read by the audience, therefore, making it impossible for me to currently estimate it's impact.\n",
    "logreg_data = final_data.drop(columns=['location','reward_levels','url','project id','name','Day of Week','Funded Date','Funded Time'])\n",
    "logreg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am also removing funding percentage and pledged ammounts because they highly correlate with whether or not something was successful\n",
    "logreg_data = logreg_data.drop(columns=['funded percentage', 'pledged'])\n",
    "logreg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(logreg_data,columns=['category','subcategory','status'],drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"max_columns\", 70) #Showing only two columns\n",
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dummy_data.corr())\n",
    "#Should I look into mutual information score or PCA?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the numbers associated with correlation, the closer to 1 a pair is, the more statistically correlated they are.\n",
    "correlation_matrix=dummy_data.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.loc[correlation_matrix['category_Design'] > 0.2,['category_Design']]\n",
    "#we see that design subcategories are highly correlated to their category of design, this makes sense a projects limits the what subcategories a project could fit into.\n",
    "#Therefore, I'm going to drop the category attribute while running my logistic regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out the values that we need to remove from the dummy data\n",
    "category_list= correlation_matrix.filter(regex = '^category').iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the category dataframe we created above and transform it into a list.\n",
    "category_columns_to_drop= list(category_list.index.values)\n",
    "category_columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's drop time of day and funded date because I don't know how to account for these things yet\n",
    "dummy_data= dummy_data.drop(columns= category_columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_data.columns\n",
    "#Double check to make sure category has been removed sucessfully, given our output we are given what we expect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dummy_data.drop('status_successful', axis=1),\n",
    "                                                   dummy_data['status_successful'], test_size=0.2,\n",
    "                                                   random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Apply feature scaling to the model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look up what these functions do\n",
    "LogReg = LogisticRegression(solver='liblinear')\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look up what these functions do\n",
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "### Classification report without cross-validation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-fold cross-validation & confusion matrices\n",
    "#calculate the prediction score for your training set\n",
    "y_train_pred = cross_val_predict(LogReg, X_train, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "### Classification report with cross-validation\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = LogReg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient Matrix')\n",
    "print(LogReg.coef_)\n",
    "# coefficients = pd.Dataframe\n",
    "print('')\n",
    "print('Training Data column names')\n",
    "print(dummy_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The coefficient dataframe from the logistic regression model does not have column names associated with it, \n",
    "# which makes it hard to quickly identify which variable corresponds to which weight.\n",
    "# \n",
    "# Fortunately, the coefficients are created in the order in which the logistic regression model received them, \n",
    "# which our dummy_data data frame was used to determine.\n",
    "# So we can combine the coefficent matrix and use the column names from dummy_data to create a dataframe of variable weights.\n",
    "\n",
    "column_names = dummy_data.drop('status_successful', axis=1).columns #we have to drop the 'status_successful' column because it was originally included in the dummy_data data frame. there is no weight assigned to \"status_successful\" becasue that's the variable we are trying to calculate.\n",
    "\n",
    "print(column_names)\n",
    "\n",
    "#create a new list of column names that shortens the subcategory names\n",
    "new_column_names= []\n",
    "\n",
    "for column in column_names:\n",
    "    new_name = column.replace(\"subcategory\",'sc')\n",
    "    new_column_names.append(new_name)\n",
    "    # print(new_column_names) Used for testing our new list\n",
    "\n",
    "# subcat_list = ['goal','backers', 'levels', 'updates', 'comments', 'duration', 'sc_Art', 'sc_Art Book', 'sc_Board & Card Games', 'sc_Childrens Book', 'sc_Classical Music', 'sc_Comics', 'sc_Conceptual Art', \n",
    "# 'sc_Country & Folk', 'sc_Crafts', 'sc_Dance', 'sc_Design', 'sc_Digital Art', 'sc_Documentary', \n",
    "# 'sc_Electronic Music', 'sc_Fashion', 'sc_Fiction', 'sc_Film & Video', 'sc_Food', 'sc_Games',\n",
    "# 'sc_Graphic Design', 'sc_Hip-Hop', 'sc_Illustration', 'sc_Indie Rock', 'sc_Jazz', 'sc_Journalism', \n",
    "# 'sc_Mixed Media', 'sc_Music', 'sc_Narrative Film', 'sc_Nonfiction', 'sc_Open Hardware', 'sc_Open Software',\n",
    "# 'sc_Painting', 'sc_Performance Art', 'sc_Periodical', 'sc_Photography', 'sc_Poetry', 'sc_Pop', 'sc_Product Design', \n",
    "# 'sc_Public Art', 'sc_Publishing', 'sc_Rock', 'sc_Sculpture', 'sc_Short Film', 'sc_Technology', 'sc_Theater', 'sc_Video Games',\n",
    "# 'sc_Webseries', 'sc_World Music']\n",
    "\n",
    "\n",
    "# print(subcat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creation of our coefficient dataframe\n",
    "coeff_df = pd.DataFrame(LogReg.coef_, columns = new_column_names)\n",
    "coeff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets reshape the matrix so that it's one column and multiple rows.\n",
    "coeff_df_transpose= coeff_df.transpose().rename(columns={0:\"Weights with Backers\"}, errors=\"raise\")\n",
    "print(coeff_df_transpose)\n",
    "#next step, let's sort the rows by their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df_transpose.sort_values('Weights with Backers')\n",
    "#backers has the highest positive weight of 38,\n",
    "#Comments had the positive wieght of 4,\n",
    "#updates had a positive weight of 1.207\n",
    "#Goal amount had a negative weight of -32.5, followed by duration at -0.2863\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS LINE OF CODE IS NO LONGER APPLICABLE SINCE WE REMOVED CATEGORIES FROM OUR MODEL\n",
    "#Pull out category weights \n",
    "# category_weights = coeff_df_transpose.filter(regex = \"^category\", axis=0)\n",
    "# category_weights.sort_values('Weights with Backers', ascending = False)\n",
    "# #Having the category of either Music, theater, or dance had a net positive effect,\n",
    "# #while everything else had a negative effect on the ability to succeed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to easily generate an array that has the value set to 1 only for the category you want. goal amount, levels, and updates \n",
    "def Backers_TestCaseGen(goal, backers, levels, updates, comments, duration, desired_subcategory):\n",
    "    parameter_list = ['goal', 'backers','levels', 'updates', 'comments', 'duration', 'sc_Art','sc_Art Book', 'sc_Board & Card Games', 'sc_Childrens Book','sc_Classical Music', 'sc_Comics', 'sc_Conceptual Art','sc_Country & Folk', 'sc_Crafts', 'sc_Dance', 'sc_Design','sc_Digital Art', 'sc_Documentary', 'sc_Electronic Music', 'sc_Fashion','sc_Fiction', 'sc_Film & Video', 'sc_Food', 'sc_Games','sc_Graphic Design', 'sc_Hip-Hop', 'sc_Illustration', 'sc_Indie Rock','sc_Jazz', 'sc_Journalism', 'sc_Mixed Media', 'sc_Music','sc_Narrative Film', 'sc_Nonfiction', 'sc_Open Hardware','sc_Open Software', 'sc_Painting', 'sc_Performance Art','sc_Periodical', 'sc_Photography', 'sc_Poetry', 'sc_Pop','sc_Product Design', 'sc_Public Art', 'sc_Publishing', 'sc_Rock','sc_Sculpture', 'sc_Short Film', 'sc_Technology', 'sc_Theater','sc_Video Games', 'sc_Webseries', 'sc_World Music']\n",
    "    pointer = parameter_list.index(desired_subcategory)\n",
    "    generated_test_case = np.zeros(len(parameter_list))\n",
    "    generated_test_case[pointer] = 1\n",
    "    generated_test_case[0] = goal\n",
    "    generated_test_case[1] = backers\n",
    "    generated_test_case[2] = levels\n",
    "    generated_test_case[3] = updates\n",
    "    generated_test_case[4] = comments\n",
    "    generated_test_case[5] = duration\n",
    "    return sc.transform(generated_test_case.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Pull out subcategory weights\n",
    "# subcategory_weights = coeff_df_transpose.filter(regex = \"^subcategory\", axis=0)\n",
    "# subcategory_weights.sort_values('Weights with Backers', ascending = False)\n",
    "# #Short film had the most postiive effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently plotting just how success rate changes given the amount of money you raise\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "plt.clf()\r\n",
    "\r\n",
    "gta = 20000 # gta = goal test amount\r\n",
    "\r\n",
    "fig = plt.figure(figsize =(10, 10))\r\n",
    "\r\n",
    "\r\n",
    "sub1 = plt.subplot(1, 2, 1)\r\n",
    "sub2 = plt.subplot(1, 2, 2)\r\n",
    "\r\n",
    "predicted_success = np.zeros(gta)\r\n",
    "\r\n",
    "for x in range(gta):\r\n",
    "    test_case = Backers_TestCaseGen(x,0,0,0,0,0,'sc_Theater')\r\n",
    "    predicted_success[x] = LogReg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "x_values = list(range(gta))    \r\n",
    "y = predicted_success.reshape(-1,1)\r\n",
    "sub1.plot(x_values, y)\r\n",
    "\r\n",
    "\r\n",
    "# as we can see, we see an extreme drop off once we get a threshold value\r\n",
    "\r\n",
    "for x in range(gta):\r\n",
    "    test_case = Backers_TestCaseGen(x,5,5,5,5,0,'sc_Theater')\r\n",
    "    predicted_success[x] = LogReg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "x_values = list(range(gta))    \r\n",
    "y = predicted_success.reshape(-1,1)\r\n",
    "sub2.plot(x_values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see what we get when you pull-out category and the number of backers from our model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummies is function built into pandas that will create binary columns for us for categorical variables.\n",
    "\n",
    "dummy_data = pd.get_dummies(logreg_data,columns=['subcategory','status'],drop_first = True)\n",
    "#Let's drop time of day and funded date because I don't know how to account for these things yet\n",
    "#let's also get rid of backers because of how strong of an impact it had on everything. \n",
    "#Let's get rid of category to see just how important subcategory is for this analysis\n",
    "dummy_data= dummy_data.drop(columns= [\"backers\",'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dummy_data.drop('status_successful', axis=1),\n",
    "                                                   dummy_data['status_successful'], test_size=0.2,\n",
    "                                                   random_state=200)\n",
    "print(X_train.shape)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "LogReg = LogisticRegression(solver='liblinear',class_weight = 'balanced')\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "### Classification report without cross-validation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-fold cross-validation & confusion matrices\n",
    "#calculate the prediction score for your training set\n",
    "y_train_pred = cross_val_predict(LogReg, X_train, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report with cross-validation\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ROC curve to assess the tradeoff between sensitivity and specificity\n",
    "y_pred_proba = LogReg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save my coefficients into a pretty dataframe\n",
    "column_names = (dummy_data.drop('status_successful', axis=1).columns)\n",
    "hardcode_columns = ['goal', 'levels', 'updates', 'comments', 'duration', 'sc_Art',\n",
    "'sc_Art Book', 'sc_Board & Card Games',\n",
    "'sc_Childrens Book', 'sc_Classical Music',\n",
    "'sc_Comics', 'sc_Conceptual Art',\n",
    "'sc_Country & Folk', 'sc_Crafts', 'sc_Dance',\n",
    "'sc_Design', 'sc_Digital Art',\n",
    "'sc_Documentary', 'sc_Electronic Music',\n",
    "'sc_Fashion', 'sc_Fiction',\n",
    "'sc_Film & Video', 'sc_Food', 'sc_Games',\n",
    "'sc_Graphic Design', 'sc_Hip-Hop',\n",
    "'sc_Illustration', 'sc_Indie Rock',\n",
    "'sc_Jazz', 'sc_Journalism', 'sc_Mixed Media',\n",
    "'sc_Music', 'sc_Narrative Film',\n",
    "'sc_Nonfiction', 'sc_Open Hardware',\n",
    "'sc_Open Software', 'sc_Painting',\n",
    "'sc_Performance Art', 'sc_Periodical',\n",
    "'sc_Photography', 'sc_Poetry', 'sc_Pop',\n",
    "'sc_Product Design', 'sc_Public Art',\n",
    "'sc_Publishing', 'sc_Rock', 'sc_Sculpture',\n",
    "'sc_Short Film', 'sc_Technology',\n",
    "'sc_Theater', 'sc_Video Games',\n",
    "'sc_Webseries', 'sc_World Music']\n",
    "\n",
    "no_backers_coeff_df = pd.DataFrame(LogReg.coef_, columns = hardcode_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no_backers_coeff_df = no_backers_coeff_df\n",
    "\n",
    "print(no_backers_coeff_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = {'backers': 'NA'}\n",
    "no_backers_coeff_df = no_backers_coeff_df.append(df2,ignore_index=True)\n",
    "\n",
    "# print(no_backers_coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose the dataframe to make it easier to read\n",
    "\n",
    "\n",
    "# print(no_backers_coeff_df)\n",
    "no_backers_coeff_df_transpose= no_backers_coeff_df.transpose()\n",
    "\n",
    "# print(no_backers_coeff_df_transpose)\n",
    "\n",
    "\n",
    "no_backers_coeff_df_transpose.drop(columns = [1],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no_backers_coeff_df_transpose= no_backers_coeff_df_transpose.rename(columns={0:\"Weights with No Backers\"}, errors=\"raise\")\n",
    "# no_backers_coeff_df_transpose.sort_values('Weights with No Backers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take the weights from the training model before and after we removed # of backers and categories from the equation\n",
    "#Let's see how it differs.\n",
    "weight_compare = pd.merge(coeff_df_transpose, no_backers_coeff_df_transpose, left_index= True, right_index=True)\n",
    "\n",
    "\n",
    "weight_comparison = weight_compare.sort_values(by = 'Weights with Backers',inplace= False)\n",
    "# print(weight_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently attempting of converting weights into their respective probabilities\n",
    "\n",
    "weight_comparison['Weights with Backers'][0]\n",
    "# np.exp(weight_comparison['Weights with Backers'][0])\n",
    "print(weight_comparison['Weights with No Backers']['backers'])\n",
    "\n",
    "print(np.exp(weight_comparison['Weights with No Backers']['backers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalculate coefficients to represent odds rather than the logit\n",
    "#this is calcualted using odds = exp(coefficient)\n",
    "\n",
    "# odds_comparison = weight_comparison\n",
    "# odds_comparison['Weights with Backers'] = math.exp(odds_comparison['Weights with Backers'])\n",
    "# print(odds_comparison.iloc[0,0])\n",
    "\n",
    "# odds_comparison = pd.DataFrame(columns = ['Weights with Backers', 'Weights With No Backers'])\n",
    "# # odds_comparison.head()\n",
    "# for x in weight_comparison['Weights with Backers']:\n",
    "# #     print(x)\n",
    "#     weight_comparison['Odds with Backers'] = math.exp(x)\n",
    "#     print(weight_comparison['Odds with Backers'])\n",
    "    \n",
    "\n",
    "# odds_comparison = weight_comparison.copy()\n",
    "weight_comparison['Odds with Backers'] = np.exp(weight_comparison['Weights with Backers'])\n",
    "\n",
    "\n",
    "# weight_comparison['Odds with No Backers'] = np.exp(weight_comparison['Weights with No Backers'])\n",
    "\n",
    "\n",
    "weight_comparison.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x= weight_comparison['Weights with Backers'].index, y=  weight_comparison['Weights with Backers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do a Grouped chart with all the variables\n",
    "#As expected the chart is difficult to read due to the large difference in values, so we are going to create two additional charts,\n",
    "#one chart will only include subcategory weights while the other will have everything else.\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "labels = weight_comparison.index\n",
    "\n",
    "new_labels =[]\n",
    "for item in labels:\n",
    "    new_labels.append(item.lstrip('sc_'))\n",
    "\n",
    "# print(new_labels)\n",
    "\n",
    "x = np.arange(len(new_labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "a4_dims = (11.7, 8.27)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "\n",
    "rects1 = ax.bar(x - width/2,  weight_comparison['Weights with Backers'], width, label='Weights that Include backers', color = 'violet')\n",
    "rects2 = ax.bar(x + width/2, weight_comparison['Weights with No Backers'], width, label='Weights W/o Backers', color = 'purple')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Attribute Weight')\n",
    "ax.set_title('Logistic Regression Weight by Attribute')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(new_labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's pull out all the values associated only with the subcategory weights\n",
    "\n",
    "final_weights_subcategory = weight_comparison.filter(like='_', axis =0)\n",
    "\n",
    "plt.clf()\n",
    "labels = final_weights_subcategory.index\n",
    "\n",
    "new_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    new_labels.append(label.lstrip('sc_'))\n",
    "\n",
    "x = np.arange(len(new_labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "a4_dims = (14, 8.27)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "\n",
    "rects1 = ax.bar(x - width/2, final_weights_subcategory['Weights with Backers'], width, label='Calculated Weights with Backers', color = 'violet')\n",
    "rects2 = ax.bar(x + width/2, final_weights_subcategory['Weights with No Backers'], width, label='Calculated Weights w/o Backers', color = 'purple')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Attribute Weight')\n",
    "ax.set_title('Weights of Subcategories on Logistic Regression Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(new_labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We graphed all the subcategories above\n",
    "#Let's go ahead and graph our values for the non subcategories entries\n",
    "#let's pull out all the values associated only with the subcategory weights\n",
    "\n",
    "final_weights_subcategory = weight_comparison.filter(items=['goal','duration','levels','updates','comments','backers'], axis =0 )\n",
    "\n",
    "plt.clf()\n",
    "labels = final_weights_subcategory.index\n",
    "\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "a4_dims = (11.7, 8.27)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "\n",
    "rects1 = ax.bar(x - width/2, final_weights_subcategory['Weights with Backers'], width, label='Weights that Include backers', color = 'violet')\n",
    "rects2 = ax.bar(x + width/2, final_weights_subcategory['Weights with No Backers'], width, label='Weights W/o Backers', color = 'purple')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.grid(color = 'grey', linestyle = '--', linewidth = 0.5, axis = 'y')\n",
    "\n",
    "ax.set_ylabel('Attribute Weight')\n",
    "ax.set_title('Weights of Non-Subcategories on Logistic Regression Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating predictions for hypothetical projects using Weights for No Backers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict probability of a project working, run the line of code \"LogReg.predict_proba([List of parameter values])\n",
    "# Use the function TestCaseGen to create an array of parameter values to use with LogReg.predict_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to easily generate an array that has the value set to 1 only for the category you want. goal amount, levels, and updates \r\n",
    "def NoBackers_TestCaseGen(goal, levels, updates, comments, duration, desired_subcategory):\r\n",
    "    parameter_list = ['goal', 'levels', 'updates', 'comments', 'duration', 'sc_Art','sc_Art Book', 'sc_Board & Card Games', 'sc_Childrens Book','sc_Classical Music', 'sc_Comics', 'sc_Conceptual Art','sc_Country & Folk', 'sc_Crafts', 'sc_Dance', 'sc_Design','sc_Digital Art', 'sc_Documentary', 'sc_Electronic Music', 'sc_Fashion','sc_Fiction', 'sc_Film & Video', 'sc_Food', 'sc_Games','sc_Graphic Design', 'sc_Hip-Hop', 'sc_Illustration', 'sc_Indie Rock','sc_Jazz', 'sc_Journalism', 'sc_Mixed Media', 'sc_Music','sc_Narrative Film', 'sc_Nonfiction', 'sc_Open Hardware','sc_Open Software', 'sc_Painting', 'sc_Performance Art','sc_Periodical', 'sc_Photography', 'sc_Poetry', 'sc_Pop','sc_Product Design', 'sc_Public Art', 'sc_Publishing', 'sc_Rock','sc_Sculpture', 'sc_Short Film', 'sc_Technology', 'sc_Theater','sc_Video Games', 'sc_Webseries', 'sc_World Music']\r\n",
    "    generated_test_case = np.zeros(len(parameter_list))\r\n",
    "    generated_test_case[0] = goal\r\n",
    "    generated_test_case[1] = levels\r\n",
    "    generated_test_case[2] = updates\r\n",
    "    generated_test_case[3] = comments\r\n",
    "    generated_test_case[4] = duration\r\n",
    "    if desired_subcategory != 'sc_Animation':\r\n",
    "        pointer = parameter_list.index(desired_subcategory)\r\n",
    "        generated_test_case[pointer] = 1\r\n",
    "    \r\n",
    "    return sc.transform(generated_test_case.reshape(1,-1))\r\n",
    "    \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\r\n",
    "# results\r\n",
    "NoBackers_TestCaseGen(0,0,0,0,0,'sc_Animation')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently plotting just how success rate changes given the amount of money you raise\n",
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "gta = 10000 # gta = goal test amount\n",
    "\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "\n",
    "\n",
    "sub1 = plt.subplot(1, 2, 1)\n",
    "sub2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "predicted_success = np.zeros(gta)\n",
    "\n",
    "for x in range(gta):\n",
    "    test_case = NoBackers_TestCaseGen(x,0,0,0,0,'sc_Theater')\n",
    "    predicted_success[x] = LogReg.predict_proba(test_case.reshape(1,-1))[0][1]\n",
    "x_values = list(range(gta))    \n",
    "y = predicted_success.reshape(-1,1)\n",
    "sub1.plot(x_values, y)\n",
    "\n",
    "\n",
    "# as we can see, we see an extreme drop off once we get a threshold value\n",
    "\n",
    "for x in range(gta):\n",
    "    test_case = NoBackers_TestCaseGen(x,5,5,5,0,'sc_Theater')\n",
    "    predicted_success[x] = LogReg.predict_proba(test_case.reshape(1,-1))[0][1]\n",
    "x_values = list(range(gta))    \n",
    "y = predicted_success.reshape(-1,1)\n",
    "sub2.plot(x_values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating my logistic regression model to not have outliers\n",
    "\n",
    "Originally I was having issues getting accurate results from my model and I assumed that it was because of the outliers in the data. It turns out that I wasn't properly scalling my input features like I needed to! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quartile_range= (final_data['goal'].percentile(75) - final_data['goal'].percentile(75))\n",
    "iq_range= np.percentile(dummy_data['goal'],75) - np.percentile(dummy_data['goal'],25)\n",
    "outlier_limit = 1.5*iq_range +np.percentile(dummy_data['goal'],75)\n",
    "print(outlier_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_dd = dummy_data.loc[dummy_data['goal'] <= (2*outlier_limit)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(no_outlier_dd.drop('status_successful', axis=1),\n",
    "                                                   no_outlier_dd['status_successful'], test_size=0.2,\n",
    "                                                   random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\r\n",
    "X_train = sc.fit_transform(X_train)\r\n",
    "X_test = sc.transform(X_test)\r\n",
    "no_outlier_logreg = LogisticRegression(solver='lbfgs')\r\n",
    "no_outlier_logreg.fit(X_train, y_train)\r\n",
    "y_pred = no_outlier_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_pred)\r\n",
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "### Classification report without cross-validation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-fold cross-validation & confusion matrices\n",
    "#calculate the prediction score for your training set\n",
    "y_train_pred = cross_val_predict(no_outlier_logreg, X_train, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "#Classification report with cross-validation\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ROC curve to assess the tradeoff between sensitivity and specificity\n",
    "y_pred_proba = no_outlier_logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(no_outlier_logreg.coef_)\r\n",
    "coed_df= no_outlier_dd.drop('status_successful',axis=1).columns\r\n",
    "print(coed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creation of our coefficient dataframe\n",
    "no_outlier_coeff_df = pd.DataFrame(no_outlier_logreg.coef_, columns = coed_df)\n",
    "no_outlier_coeff_df.head()\n",
    "\n",
    "\n",
    "#updated weights make a ton of sense with comments being the strongest indicator or project success, this makes sense because comments can be used as a secondary effect measure of project popularity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now test to see if these weight actually produce accruate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Subplot example ######\r\n",
    "\r\n",
    "# fig = plt.figure(figsize=(20, 10))\r\n",
    "# print(fig)\r\n",
    "\r\n",
    "# fig.suptitle('Subplot example3-1: Add subplot later', fontsize=20)\r\n",
    "\r\n",
    "# # Add plots\r\n",
    "# ax1 = fig.add_subplot(1, 3, 1)\r\n",
    "# ax1.plot(x, y)\r\n",
    "# ax1.set_xlabel('X label, plot1')\r\n",
    "# ax1.set_ylabel('Y label, plot1')\r\n",
    "# ax1.set_xticklabels('')\r\n",
    "# ax1.set_yticklabels('')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently plotting just how success rate changes given the amount of money you raise\r\n",
    "plt.clf()\r\n",
    "\r\n",
    "\r\n",
    "gta = 20000 # gta = goal test amount\r\n",
    "lta = 10 #cta = levels test ammount\r\n",
    "uta = 10 #uta = update test ammount\r\n",
    "cta = 10 #cta = comment test ammount\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(20, 10))\r\n",
    "fig.suptitle('Probability Calculations based on Non-Outlier Model', fontsize=20)\r\n",
    "\r\n",
    "\r\n",
    "ax1 = fig.add_subplot(1,3,1)\r\n",
    "ax1.set(xlim=[0,gta],ylim=[0,1.0])\r\n",
    "ax1.set_xlabel('Goal $ Amount',fontsize=18)\r\n",
    "\r\n",
    "\r\n",
    "ax2 = fig.add_subplot(1,3,2)\r\n",
    "ax2.set(xlim=[0,gta],ylim=[0,1.0])\r\n",
    "ax2.set_xlabel('Goal $ Amount',fontsize=18)\r\n",
    "\r\n",
    "\r\n",
    "ax3 = fig.add_subplot(1,3,3)\r\n",
    "ax3.set(xlim=[0,gta],ylim=[0,1.0])\r\n",
    "ax3.set_xlabel('Goal $ Amount',fontsize=18)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "predicted_success = np.zeros(gta)\r\n",
    "\r\n",
    "x_values = list(range(gta))    \r\n",
    "\r\n",
    "\r\n",
    "i = 0; \r\n",
    "for levels in range(lta):\r\n",
    "    for x in range(gta):\r\n",
    "        test_case = NoBackers_TestCaseGen(x,levels,0,0,0,'sc_Art')\r\n",
    "        predicted_success[x] = no_outlier_logreg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "    y = predicted_success\r\n",
    "    ax1.plot(x_values, y, label = 'Levels =' + \" \" + str(i))\r\n",
    "    i += 1\r\n",
    "\r\n",
    "\r\n",
    "# #as we can see, we see an extreme drop off once we get a threshold value\r\n",
    "i = 0; \r\n",
    "for updates in range(uta):\r\n",
    "    for x in range(gta):\r\n",
    "        test_case = NoBackers_TestCaseGen(x,0,updates,0,0,'sc_Art')\r\n",
    "        predicted_success[x] = no_outlier_logreg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "    y = predicted_success\r\n",
    "    ax2.plot(x_values, y, label = 'Updates =' + \" \" + str(i))\r\n",
    "    i += 1\r\n",
    "\r\n",
    "i = 0; \r\n",
    "for comments in range(cta):\r\n",
    "    for x in range(gta):\r\n",
    "        test_case = NoBackers_TestCaseGen(x,0,0,comments,0,'sc_Art')\r\n",
    "        predicted_success[x] = no_outlier_logreg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "    y = predicted_success\r\n",
    "    ax3.plot(x_values, y,label = 'Comments =' + \" \" + str(i))\r\n",
    "    i += 1\r\n",
    "\r\n",
    "ax1.legend(loc = 'best')\r\n",
    "ax2.legend(loc = 'best')\r\n",
    "ax3.legend(loc = 'best')\r\n",
    "\r\n",
    "# fig.tight_layout()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case= NoBackers_TestCaseGen(1,0,0,0,0,'sc_Art')\r\n",
    "# print(no_outlier_logreg.predict_proba(test_case.reshape(1,-1))[0][1])\r\n",
    "\r\n",
    "\r\n",
    "test_case1= NoBackers_TestCaseGen(1,0,0,0,0,'sc_Art')\r\n",
    "print(no_outlier_logreg.predict_proba(test_case1.reshape(1,-1))[0][1])\r\n",
    "\r\n",
    "for x in range(10):\r\n",
    "    test_case = NoBackers_TestCaseGen(x,0,0,0,0,'sc_Art')\r\n",
    "    predicted_success[x] = no_outlier_logreg.predict_proba(test_case.reshape(1,-1))[0][1]\r\n",
    "    print(x)\r\n",
    "print(predicted_success.reshape(-1,1))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0; \r\n",
    "limit = 10\r\n",
    "gta = 5\r\n",
    "comment_success = np.zeros(gta)\r\n",
    "update_success = np.zeros(gta)\r\n",
    "\r\n",
    "for index in range(limit):\r\n",
    "    print(index)\r\n",
    "    for x in range(gta):\r\n",
    "        comments_tc = NoBackers_TestCaseGen(x,0,0,index,0,'sc_Art')\r\n",
    "        comment_success[x] = no_outlier_logreg.predict_proba(comments_tc.reshape(1,-1))[0][1]\r\n",
    "        updates_tc = NoBackers_TestCaseGen(x,0,index,0,0,'sc_Art')\r\n",
    "        update_success[x] = no_outlier_logreg.predict_proba(updates_tc.reshape(1,-1))[0][1]\r\n",
    "    y = comment_success\r\n",
    "    y1 = update_success\r\n",
    "    # ax2.plot(x_values, y, '-b',label = 'Comments =' + \" \" + str(i))\r\n",
    "    print(\"Comments\")\r\n",
    "    print(y)\r\n",
    "    print(\"Updates\")\r\n",
    "    print(update_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NoBackers_TestCaseGen(0,0,1,0,0,'sc_Art') - NoBackers_TestCaseGen(0,0,0,0,0,'sc_Art'))\r\n",
    "print(NoBackers_TestCaseGen(0,0,0,1,0,'sc_Art') - NoBackers_TestCaseGen(0,0,0,0,0,'sc_Art'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_data.columns)\r\n",
    "len(dummy_data.columns) - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data['subcategory'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0eeda52a798dd57b2ef8e13888075653d22071a8bc304d44073bbf5a37bcf9649"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}